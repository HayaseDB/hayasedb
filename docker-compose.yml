networks:
  public:
    external: true
  internal:

volumes:
  postgres_data:
  minio_data:

services:
  postgres:
    image: postgres:17-alpine
    networks:
      - internal
    hostname: postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-hayasedb}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-hayasedb}"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s
    stop_grace_period: 10s
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      update_config:
        parallelism: 1
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  minio:
    image: minio/minio:latest
    networks:
      public:
      internal:
    hostname: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:?MINIO_ROOT_PASSWORD is required}
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s
    stop_grace_period: 10s
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      update_config:
        parallelism: 1
        delay: 5s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.minio-console.rule=Host(`${MINIO_CONSOLE_DOMAIN:?MINIO_CONSOLE_DOMAIN is required}`)"
        - "traefik.http.routers.minio-console.entrypoints=web"
        - "traefik.http.services.minio-console.loadbalancer.server.port=9001"

  api:
    image: ghcr.io/hayasedb/hayasedb-api:${API_IMAGE_TAG:-latest}
    networks:
      public:
      internal:
    environment:
      API_PORT: 3000
      API_ENV: ${API_ENV:-production}
      API_CORS_ORIGIN: ${API_CORS_ORIGIN:-}
      API_SWAGGER_ENABLED: ${API_SWAGGER_ENABLED:-false}
      API_SWAGGER_PATH: ${API_SWAGGER_PATH:-docs}
      API_DATABASE_HOST: postgres
      API_DATABASE_PORT: 5432
      API_DATABASE_NAME: ${POSTGRES_DB:-hayasedb}
      API_DATABASE_USERNAME: ${POSTGRES_USER:-postgres}
      API_DATABASE_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}
      API_DATABASE_SYNCHRONIZE: "false"
      API_DATABASE_LOGGING: ${API_DATABASE_LOGGING:-false}
    depends_on:
      - postgres
      - minio
    healthcheck:
      test: ["CMD", "node", "-e", "fetch('http://localhost:3000/health/ready').then(r => process.exit(r.ok ? 0 : 1)).catch(() => process.exit(1))"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 60s
    stop_grace_period: 30s
    deploy:
      mode: replicated
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        monitor: 45s
        failure_action: rollback
        order: start-first
        max_failure_ratio: 0
      rollback_config:
        parallelism: 1
        delay: 5s
        monitor: 10s
        failure_action: pause
        order: stop-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.api.rule=Host(`${API_DOMAIN:?API_DOMAIN is required}`)"
        - "traefik.http.routers.api.entrypoints=web"
        - "traefik.http.services.api.loadbalancer.server.port=3000"
